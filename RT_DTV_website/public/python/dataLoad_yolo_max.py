import numpy as np
import torch
import pandas as pd
import torch.nn as nn
import torch.utils
import torch.utils.data
from torchvision import datasets
from torchvision import transforms
from torch.nn.utils.rnn import pad_sequence
import os
from tqdm import tqdm
from PIL import Image
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import sys

import config_max

# You can modify hyperparemeter
train_batch_size = config_max.train_batch_size
# train_batch_size = 8
test_batch_size = config_max.test_batch_size
window_size = config_max.window_size
# window_size = 30
step = config_max.step # æ”¹æˆ 5 æ™‚ train accuracy åœ¨ 0.5~0.6 ä»¥ä¸‹
num_workers = config_max.num_workers
train_size_rate = config_max.train_size_rate   # Split dataset into train and validation 8:2

# Image transform for train and test
data_transforms = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
test_transforms = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Make dataset and dataloader
def make_train_dataloader(img_path, label_path):
    # æ¯æ¬¡ç”¨ __getitem__ ç¢°ä¸€æ¬¡ datasetï¼Œæœƒå›å‚³çš„ä¸€ç­†è³‡æ–™ï¼ŒåŒ…å« img_list_tensorã€labels_tensorã€img_list_name
    # img_list_tensor çš„å½¢ç‹€ç‚º (window_size, C, H, W)
    dataset = Dataset_car_list(img_path = img_path, label_path = label_path, transform = data_transforms)
    train_size = int(len(dataset) * train_size_rate)
    valid_size = len(dataset) - train_size
    train_dataset = torch.utils.data.Subset(dataset, range(0, train_size))
    valid_dataset = torch.utils.data.Subset(dataset, range(train_size, len(dataset)))
    # train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])
    # æ¯ç¢°ä¸€æ¬¡ train_loader ä¹Ÿæ˜¯æœƒå›å‚³ img_list_tensor_batch ã€ labels_tensor_batch ã€ img_list_name_batch ï¼Œåªæ˜¯å¤šäº†ä¸€å€‹ç¶­åº¦ï¼Œç”¨ batch çš„æ•¸é‡çµ„åˆåœ¨ä¸€èµ·
    # ä¾‹å¦‚ img_list_tensor_batch çš„å½¢ç‹€ç‚º (batch_size, window_size, C, H, W)
    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn)
    valid_loader = DataLoader(valid_dataset, batch_size=train_batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn)

    return train_loader, valid_loader

def make_test_dataloader(data_path):
    datasets = Dataset_car_list(img_path = data_path, transform = data_transforms, mode = "test")
    test_loader = DataLoader(datasets, batch_size=test_batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn_test)
    return test_loader

class Dataset_car_list(Dataset):
    def __init__(self, img_path, label_path = None, transform = None, mode = 'train'):
        if mode == 'train':
            # image_files = [
            #     window_list = [
            #         [video_name, frame, img_path, label],
            #         (å…± window_size ç­†è³‡æ–™)
            #     ], (æ²’æœ‰ car_id çš„è³‡æ–™ï¼Œæ‰€æœ‰ window_list ä¸²æˆ image_filesï¼Œå…±æœ‰æ‰€æœ‰ car çš„æ•¸é‡ * æ¯è¼›è»Šåˆ†æˆçš„ window_list æ•¸é‡)
            # ]
            image_files = split_images_to_car_list(img_path, label_path)
        elif mode == 'test':
            # image_files = [
                # car_list_i =  [
                    # [video_name, frame, img_path, label], ... (frame_listï¼ŒåŒ…å«æ­¤å¹€çš„ç›¸é—œè³‡æ–™)
                    # (å…±æœ‰æ­¤è³‡æ–™å¤¾å…§çš„æ‰€æœ‰ car_imgï¼Œå› æ­¤å¯èƒ½æœ‰æ¥è¿‘ 200 å¹€çš„è³‡æ–™åœ¨ä¸€å€‹ car_list_i å…§)
                # ], (æœ‰è¨±å¤š car_list_iï¼Œæ•¸é‡ç­‰åŒæ–¼ test è³‡æ–™å¤¾å…§çš„å½±ç‰‡è³‡æ–™å¤¾æ•¸é‡ï¼Œä¹Ÿå› æ­¤æ¯å€‹è³‡æ–™å¤¾å…§åªèƒ½æ”¾åƒ…é™ä¸€å€‹ car_id çš„è»Šè¼›æˆªåœ–çµ„)
            # ]
            image_files = car_list_from_folder(img_path)
        self.image_files = image_files
        self.transform = transform
        self.mode = mode

    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        try:
            # idx æ±ºå®šæ˜¯å“ªå€‹ window_list æˆ–è€…å“ªå€‹ car_list_i
            img_list = []
            labels = []
            img_list_name = self.image_files[idx][0][0]

    # img_len åœ¨ train æ™‚å°±æ˜¯ window_sizeï¼Œåœ¨ test æ™‚å°±æ˜¯ car_list_i å…§çš„å½±åƒæ•¸é‡
            img_len = len(self.image_files[idx])
            for i in range(img_len):
                img_path = self.image_files[idx][i][2]
                label = self.image_files[idx][i][3]
                img = Image.open(img_path).convert('RGB')
                if self.transform:  # å°å½±åƒé€²è¡Œ preprocess
                    img = self.transform(img)
                img_list.append(img)
                labels.append(label)
            img_list_tensor = torch.stack(img_list)
            labels_tensor = torch.tensor(labels)
            if self.mode == 'train':
                # å›å‚³ä¸€ç­†è³‡æ–™
                return img_list_tensor, labels_tensor, img_list_name
            elif self.mode == 'test':
                return img_list_tensor, labels_tensor, img_list_name
            
        except Exception as e:
        # æ‰¾å‡ºæ˜¯å“ªå€‹ car folder å‡ºéŒ¯
            folder_hint = self.image_files[idx][0][2].split(os.sep)
            folder_name = folder_hint[-2] if len(folder_hint) > 2 else "æœªçŸ¥è³‡æ–™å¤¾"
            print(f"[âŒ IndexError] è®€å–ç¬¬ {idx} ç­† self.image_files æ™‚å‡ºéŒ¯ï¼ä¾†è‡ªè³‡æ–™å¤¾ï¼š{folder_name}")
            print(f"[ğŸ DEBUG] img_list_name: {img_list_name}")
            print(f"[ğŸ DEBUG] éŒ¯èª¤è¨Šæ¯ï¼š{e}")
            raise e  # ç¹¼çºŒä¸Ÿå‡ºä¾‹å¤–è®“ä¸»ç¨‹å¼çŸ¥é“


def split_images_to_car_list(img_folder, label_path):
    car_list = []
    combined_label = []
    for label_file in os.listdir(label_path):
        if label_file.endswith(".csv"):
            file_path = os.path.join(label_path, label_file)
            # print(file_path)
            df = pd.read_csv(file_path)
            combined_label.append(df)
    combined_label_df = pd.concat(combined_label, ignore_index=True)
    # å°‡æ‰€æœ‰ label çš„ csv æª”æ¡ˆçš„è³‡è¨Šåˆä½µæˆä¸€å€‹ DataFrame ä¸¦é‡æ–°ç´¢å¼•
    # ä¾‹å¦‚ï¼Œå‡è¨­ combined_label ç‚ºï¼š
    # [
    #      ID   Name
    #   0   1  Alice
    #   1   2    Bob
    #   ,
    #      ID     Name
    #   0   7  Charlie
    #   1   8   David
    # ]
    # åˆä½µå¾Œçš„ combined_label_df ç‚ºï¼š
    #        ID   Name
    #    0   1   Alice
    #    1   2     Bob
    #    2   7  Charlie
    #    3   8   David
    print(combined_label_df)
    
    combined_label_df = check_files_and_count_labels_and_turn_light(data_path, combined_label_df)
    
    # iterrows() é€è¡Œè®€å– combined_label_df çš„ DataFrameï¼Œæ¯ä¸€è¡Œä»£è¡¨ä¸€è¼›è»Šçš„è³‡è¨Š
    for index, row in combined_label_df.iterrows():
        windows_list = []
        name = row["filename"]
        car_id = row["carid"]
        begin_frame = row["begin"]
        end_frame = row["end"]
        # row.to_list() æœƒå°‡ row è½‰æ›ç‚º [name, car_id, begin_frame, end_frame, frame_1, frame_2, ..., frame_n]
        tmp_car_list = row.to_list()
        
        # # æ¯è¡Œ (æ¯å€‹ car_id) åˆ†æˆæ•¸å€‹ windowï¼Œä¸²æ¥åˆ°ä¸€å€‹ windows_list ä¸‹
        # for start in range(begin_frame, end_frame - window_size, step):
        #     window_list = []
        #     for i in range(window_size):
        #         img_path = os.path.join(img_folder,name ,"car" + str(car_id) + "_" + str(start + i) +".jpg")
        #         # æ¯å€‹ window åŒ…å«ä»¥ä¸‹æ¬„ä½ [filename, ç•¶å‰çš„ frame_num, img_path, ç•¶å‰ frame çš„è»Šç‡ˆäº®æš—æ¨™è¨˜å€¼ (-1,0,1)]
        #         # ä¹Ÿå°±æ˜¯ [video_name, frame, img_path, label]
        #         # tmp_car_list é€™å€‹ row çš„æ¬„ä½è½‰ç‚º listï¼Œè€Œç·¨è™Ÿç‚º start+i çš„ frame æœ¬æ‡‰åœ¨ tmp_car_list[start+i-1]ï¼Œä½†é–‹é ­è¦è·³éå››å€‹æ¬„ä½ (filename,carid,begin,end)ï¼Œæ‰€ä»¥åŠ å››å¾Œè®Šç‚º tmp_car_list[start + i + 3]
        #         window_list.append([row['filename'], start + i, img_path, int(tmp_car_list[start + i + 3])])
        #     windows_list.append(window_list)
        # # windows_list = [[[row['filename'], start + i, 'path', int(tmp_car_list[start + i + 3]) ] for i in range(window_size)] for start in range(begin_frame, end_frame - window_size, step)]
        # # car_list.extend(windows_list) æ˜¯å°‡ windows_list å…§çš„æ‰€æœ‰å…ƒç´ åŠ å…¥ car_listï¼Œè€Œä¸æ˜¯æŠŠ windows_list ç•¶ä½œä¸€å€‹æ•´é«”åŠ å…¥
        # # æ‰€ä»¥ä¸¦æ²’æœ‰åƒ windows_list é‚£æ¨£å€åˆ†ä¸åŒçš„ caridï¼Œè€Œæ˜¯æŠŠæ‰€æœ‰çš„ window éƒ½ä¸²åœ¨åŒä¸€å€‹ list å…§
        # car_list.extend(windows_list)
        
        # æˆ‘ç¨å¾®ä¿®æ”¹ï¼Œå–æ¶ˆç„¡æ„ç¾©çš„ windows_listï¼Œç›´æ¥å°‡ window æ¥åˆ° car_list ä¸‹é¢
        # for start in range(begin_frame, end_frame - window_size, step):
        #     window_list = []
        #     for i in range(window_size):
        #         img_path = os.path.join(img_folder,name ,"car" + str(car_id) + "_" + str(start + i) +".jpg")
        #         window_list.append([row['filename'], start + i, img_path, int(tmp_car_list[start + i + 3])])
        #     car_list.append(window_list)
        
        valid_frames = []
        # æƒæè©²è»Šçš„æ‰€æœ‰ frameï¼ŒæŒ‘å‡ºåˆæ³•çš„ï¼ˆlabel â‰  -1 ä¸”åœ–ç‰‡å­˜åœ¨ï¼‰
        for frame in range(begin_frame, end_frame):
            label = int(tmp_car_list[frame + 3])
            if label != -1:
                img_path = os.path.join(img_folder, name, f"car{car_id}_{frame}.jpg")
                if os.path.exists(img_path):
                    valid_frames.append([name, frame, img_path, label])

        # ç”¨æ»‘å‹•è¦–çª—æ–¹å¼å°‡åˆæ³• frame åˆ†çµ„
        for start in range(0, len(valid_frames) - window_size + 1, step):
            window = valid_frames[start : start + window_size]
            if len(window) == window_size:
                car_list.append(window)
                
    # print(car_list[2][0])
    # print(len(car_list),len(car_list[2]))
    # car_list æ¶æ§‹ï¼š
    # ä¸€å€‹ä¸‰ç¶­çš„ listï¼ŒåŒ…å«æ‰€æœ‰ car (car_id) çš„ window_list
    # æ¯å€‹ window list åŒ…å«æ•¸é‡å›ºå®šç‚º window_size çµ„çš„è³‡æ–™
    # æ¯ç­†è³‡æ–™åŒ…å« 4 å€‹æ¬„ä½ï¼š[filename, ç•¶å‰çš„ frame_num, img_path, ç•¶å‰ frame çš„è»Šç‡ˆäº®æš—æ¨™è¨˜å€¼ (-1,0,1)]
    
    # car_list = [
    #     window_list, window_list, ..., window_list # æ•¸é‡ç‚º (æ‰€æœ‰ csv æª”æ¡ˆçš„ row æ•¸é‡ (æ¯è¼›è»Š) ) * (æ¯è¼›è»Šåˆ†å‰²æˆçš„ window_list æ•¸é‡)
    #     ä¸å« windows_listï¼Œå› ç‚º car_list å°±æ˜¯å¾ˆå¤š windows_listã€åˆä½µã€‘(ä¸æ˜¯ä¸²æ¥)
    # ] 
    # window_list = [
        # å›ºå®šæœ‰ window_size ç­†è³‡æ–™
        # [filename, ç•¶å‰çš„ frame_num, img_path, ç•¶å‰ frame çš„è»Šç‡ˆäº®æš—æ¨™è¨˜å€¼ (-1,0,1)], [filename, ç•¶å‰çš„ frame_num, img_path, ç•¶å‰ frame çš„è»Šç‡ˆäº®æš—æ¨™è¨˜å€¼ (-1,0,1)], ... # å…±æœ‰ window_size çµ„è³‡æ–™
    # ]
    # car_list = [
    #    window_list = [
    #        [filename, ç•¶å‰çš„ frame_num, img_path, ç•¶å‰ frame çš„è»Šç‡ˆäº®æš—æ¨™è¨˜å€¼ (-1,0,1)], ... (window_size çµ„)
    #    ], ..., (å°‡ carimg ä»¥ window_size å’Œ step åˆ†çµ„ï¼Œä¸åˆ† carid éƒ½ä¸²æ¥åœ¨ car_list ä¹‹ä¸‹)
    # ]
    return car_list

def car_list_from_folder(directory):
    car_list = []
    for video_name in os.listdir(directory):
        video_path = os.path.join(directory, video_name)
        car_list_i = []
        for img in os.listdir(video_path):
            if not img.lower().endswith('.jpg'):  # ç¢ºä¿å‰¯æª”åç‚º .jpgï¼ˆå¿½ç•¥å¤§å°å¯«ï¼‰
                continue  # è·³éé .jpg çš„æª”æ¡ˆ
            # ä»¥åº•ç·š "_" åˆ†å‰²æª”åï¼Œä¾‹å¦‚ "car12_001.jpg" æœƒè®Šæˆ ["car12", "001.jpg"]
            tmp_img = img.split('_')
            # carid = int(tmp_img[0][4:]) # å‡è¨­æª”åæ ¼å¼ç‚º "car12_001.jpg"ï¼Œå‰‡ `car12[4:]` å–å¾— "12" ä¸¦è½‰ç‚ºæ•´æ•¸
            # å¾æª”åå–å¾—å½±åƒçš„å¹€ç·¨è™Ÿ (frame number)ï¼Œå»æ‰å‰¯æª”å ".jpg"  
            # ä¾‹å¦‚ "car12_001.jpg" â†’ `tmp_img[1] = "001.jpg"` â†’ `[:-4]` å»æ‰ ".jpg" â†’ è½‰ç‚ºæ•´æ•¸ `1`
            frame = int(tmp_img[1][:-4])
            label = -1
            img_path = os.path.join(video_path, img)
            frame_list = [video_name, frame, img_path, label]
            car_list_i.append(frame_list)
        car_list.append(car_list_i)
    # car_list = [
        # car_list_i =  [
            # [video_name, frame, img_path, label], ... (frame_listï¼ŒåŒ…å«æ­¤å¹€çš„ç›¸é—œè³‡æ–™)
        # ], (æœ‰è¨±å¤š car_list_iï¼Œæ•¸é‡ç­‰åŒæ–¼ test è³‡æ–™å¤¾å…§çš„å½±ç‰‡è³‡æ–™å¤¾æ•¸é‡ï¼Œä¹Ÿå› æ­¤æ¯å€‹è³‡æ–™å¤¾å…§åªèƒ½æ”¾åƒ…é™ä¸€å€‹ car_id çš„è»Šè¼›æˆªåœ–çµ„)
    # ]
    return car_list

def collate_fn(batch):
    sequences = [x[0] for x in batch]
    labels = [x[1] for x in batch]
    image_list_name = [x[2] for x in batch]
    seq_len = [len(s) for s in sequences]

    seq_len = torch.tensor(seq_len)
    sequences = torch.stack(sequences)
    labels = torch.stack(labels)
    return sequences, labels, seq_len, image_list_name

def collate_fn_test(batch):
    # ç”¨æ–¼å°‡ samples çµ„åˆæˆä¸€å€‹ batch
    # å®ƒæœƒæŠŠ Dataset_car_list.__getitem__ å›å‚³çš„å–®ç­†è³‡æ–™è½‰æ›æˆæ‰¹æ¬¡å¼µé‡ (batch tensor)ï¼Œè®“æ¨¡å‹å¯ä»¥ä¸€æ¬¡è™•ç†å¤šç­†è³‡æ–™ï¼Œæé«˜é‹ç®—æ•ˆç‡ã€‚
    # batch = [
    #     [img_list_tensor, labels_tensor, img_list_name],
    #     å…± batch_size ç­†
    # ]
    # sequences æ˜¯ä¸€å€‹ listï¼ŒåŒ…å« batch_size ç­† img_list_tensor
    sequences = [x[0] for x in batch]
    # labels æ˜¯ä¸€å€‹ listï¼ŒåŒ…å« batch_size ç­† labels_tensor
    labels = [x[1] for x in batch]
    # image_list_name æ˜¯ä¸€å€‹ listï¼ŒåŒ…å« batch_size ç­† img_list_name
    image_list_name = [x[2] for x in batch]
    # ç‚ºæ¯å€‹ img_list_tensor çš„ lenï¼Œæ‡‰è©²æ˜¯ frames æ•¸é‡ï¼Œ
    seq_len = [len(s) for s in sequences]
    seq_len = torch.tensor(seq_len)
    sequences = torch.stack(sequences)
    labels = torch.stack(labels)
    return sequences, labels, seq_len, image_list_name

base_path = os.path.dirname(os.path.abspath(__file__))
data_path = os.path.join(base_path, "data", "train")
# label_path = os.path.join(base_path, "label")
# train_loader, _ = make_train_dataloader(data_path, label_path)
# print(len(train_loader))
# # test_loader = make_test_dataloader(data_path)
# for data, target, seq_len, image_list_name in tqdm(train_loader, desc="Training"):
#     print(data.shape)
#     print(target.shape)
#     print(seq_len)
#     print(image_list_name)

def check_files_and_count_labels_and_turn_light(base_dir, combined_label_df, xlsx_path=config_max.xlsx_path):
    window_size = config_max.window_size
    step = config_max.step

    # è®€å– xlsx æ¨™è¨˜æª”
    sheets = pd.read_excel(xlsx_path, sheet_name=None)
    mark_dfs = []
    for name, sheet in sheets.items():
        mark_dfs.append(sheet)
    mark_df = pd.concat(mark_dfs, ignore_index=True)

    # # å»ºç«‹æ¯å€‹è½‰å‘é¡åˆ¥çš„çµ±è¨ˆ
    # stats = {
    #     'r': {'light': 0, 'no_light': 0, 'repeat_light': 0, 'repeat_no_light': 0},
    #     'l': {'light': 0, 'no_light': 0, 'repeat_light': 0, 'repeat_no_light': 0},
    #     'other': {'light': 0, 'no_light': 0, 'repeat_light': 0, 'repeat_no_light': 0}
    # }
    # çµ±è¨ˆè¡¨ï¼škey = turn_valueï¼Œvalue = {'light', 'no_light', 'repeat_light', 'repeat_no_light'}
    stats = {}
    
    # other_turns = []  # æ”¶é›†å…¶ä»–è½‰å‘ç¨®é¡
    
    abnormal_turn_records = []  # é¡å¤–æ”¶é›† turn ç‚º nan, s, n çš„è»Š
    
    turn_list = [] 

    for idx, row in combined_label_df.iterrows():
        filename = row['filename']
        carid = row['carid']
        begin = row['begin']
        end = row['end']

        # æ‰¾å‡ºå°æ‡‰çš„æ¨™è¨˜
        matched_rows = mark_df[(mark_df['video_name'] == filename) & (mark_df['car_id'] == carid)]
        if matched_rows.empty:
            print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ° video_name = {filename}ï¼Œcar_id = {carid} çš„æ¨™è¨˜è³‡æ–™")
            continue

        matched_row = matched_rows.iloc[0]
        
        # æ±ºå®šé€™è¼›è»Šçš„è½‰å‘ç¨®é¡
        turn_value_raw = matched_row['turn']
        if pd.isna(turn_value_raw):
            turn_value = 'nan'
        else:
            turn_value = str(turn_value_raw).strip().lower()
            
        # âœ… å¦‚æœ turn ä¸æ˜¯ l/r/sï¼Œæ”¹æ‹¿ predict_turn
        if turn_value not in ['l', 'r', 's']:
            predict_turn_raw = matched_row.get('predict_turn', None)
            if pd.isna(predict_turn_raw):
                turn_value = 'nan'
            else:
                turn_value = str(predict_turn_raw).strip().lower()
            
        if turn_value in ['nan', 's', 'n']:
            abnormal_turn_records.append((filename, carid, turn_value))
            
        turn_list.append(turn_value)
            
        # å¦‚æœé€™å€‹ turn_value é‚„æ²’å‡ºç¾éï¼Œåˆå§‹åŒ–
        if turn_value not in stats:
            stats[turn_value] = {'light': 0, 'no_light': 0, 'repeat_light': 0, 'repeat_no_light': 0}
        

        # å…ˆæª¢æŸ¥æ‰€æœ‰å½±åƒæ˜¯å¦å­˜åœ¨
        for frame_num in range(begin, end + 1):
            img_path = os.path.join(base_dir, filename, f"car{carid}_{frame_num}.jpg")
            if not os.path.exists(img_path):
                print(f"æª”æ¡ˆ {img_path} ä¸å­˜åœ¨")
                sys.exit(0)
            
        # è¨ˆç®—ä¸é‡è¤‡çš„ light / no_light
        for frame_num in range(begin, end + 1):
            frame_col = f'frame_{frame_num}'
            if frame_col in row:
                value = row[frame_col]
                if value == 1:
                    stats[turn_value]['light'] += 1
                elif value == 0:
                    stats[turn_value]['no_light'] += 1
                # -1 æˆ– NaN å¿½ç•¥
            
        # è¨ˆç®—æœ‰é‡è¤‡çš„ repeat_light / repeat_no_light
        frame_num_total = end - begin + 1
        if frame_num_total >= window_size:
            for start in range(begin, end - window_size + 2, step):
                for offset in range(window_size):
                    current_frame = start + offset
                    frame_col = f'frame_{current_frame}'
                    if frame_col in row:
                        value = row[frame_col]
                        if value == 1:
                            stats[turn_value]['repeat_light'] += 1
                        elif value == 0:
                            stats[turn_value]['repeat_no_light'] += 1
                        # -1 æˆ– NaN å¿½ç•¥
                        
    # å°‡ turn_list å¯«å› combined_label_dfï¼Œæ–°å¢æ¬„ä½ turn
    combined_label_df['turn'] = turn_list
    print("æ–°å¢æ¬„ä½ turn")

    print("\n===== å„è½‰å‘é¡åˆ¥çµ±è¨ˆçµæœ =====")
    for turn, result in stats.items():
        print(f"\nè½‰å‘é¡åˆ¥ï¼šã€{turn}ã€‘")
        print(f"  light å¹€æ•¸ = {result['light']}")
        print(f"  no_light å¹€æ•¸ = {result['no_light']}")
        print(f"  repeat_light å¹€æ•¸ = {result['repeat_light']}")
        print(f"  repeat_no_light å¹€æ•¸ = {result['repeat_no_light']}")
        print(f"  total åŸå§‹å¹€æ•¸ = {result['light'] + result['no_light']}")
        print(f"  total é‡è¤‡å¹€æ•¸ = {result['repeat_light'] + result['repeat_no_light']}")

    if abnormal_turn_records:
        print("\n===== æ‰€æœ‰ turn ç‚º nan/s/n çš„è»Šè¼›è³‡æ–™ =====")
        for idx, (filename, carid, turn_value) in enumerate(abnormal_turn_records):
            print(f"{idx+1}. filename = {filename}, carid = {carid}, turn = {turn_value}")
            
        # ç§»é™¤è½‰å‘ç‚º nan/s/n çš„åˆ—ï¼Œä¸¦é‡æ’ç´¢å¼•
        combined_label_df = combined_label_df[~combined_label_df['turn'].isin(['nan', 's', 'n'])].reset_index(drop=True)
        print("å·²ç§»é™¤æ‰€æœ‰ turn ç‚º nan/s/n çš„æ¨™è¨»è³‡æ–™")
    else:
        print("\næ²’æœ‰ turn ç‚º nanã€s æˆ– n çš„è³‡æ–™")
    print("\nè¨“ç·´èˆ‡é©—è­‰è³‡æ–™çš†å­˜åœ¨ä¸”çµ±è¨ˆå®Œç•¢ï¼")
    output_csv_path = "combine_with_turn.csv" 
    combined_label_df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… å·²å„²å­˜å«è½‰å‘æ¨™è¨˜çš„æ–°æª”æ¡ˆï¼š{output_csv_path}")
    print("\combined_label_df:")
    print(f"{combined_label_df}")
    # sys.exit(0)
    return combined_label_df