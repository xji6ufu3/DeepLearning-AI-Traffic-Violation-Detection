from collections import defaultdict
import torch
import cv2
import os
import websockets
import asyncio
import json
import requests
from ultralytics import YOLO
import numpy as np
from turn import turn_predict
from light import light_predict
from turn_model import *

# åŠ å…¥ log æª”è¨˜éŒ„
log_path = os.path.join(os.getcwd(), "log.txt")
with open(log_path, "a", encoding="utf-8") as f:
    f.write("car_track_website.py è¢«è§¸ç™¼åŸ·è¡Œ\n")



device = torch.device("cuda" if torch.cuda.is_available() else "cpu") #æ”¹ç”¨CPU

base_path = os.path.join(os.getcwd(), "public", "python")
weight_path = os.path.join(base_path, "weight")
model = YOLO(os.path.join(weight_path, "yolov8n.pt"))
model.to(device)

turn_model = ResNet(ResidualBlock, [3,4,6,3])
turn_model.load_state_dict(torch.load(os.path.join(weight_path, "turn.pth"), map_location=device))
turn_model = turn_model.to(device)


light_model = YOLO(os.path.join(weight_path, "light.pt"))
light_model = light_model.to(device)



async def car_track(video_path, output_folder, websocket = None, auto = 1, video_source = "unknown"):



    ##################################
    filename = os.path.basename(video_path)[:-4]
    print(filename)
    car_info = defaultdict(dict)
    buffer = []
    #ç›®å‰æª¢æ¸¬åˆ°çš„æœªé›¢é–‹ç•«é¢çš„è»Šè¼›
    record_cars = set()
    frame_num = 0
    # ç´€éŒ„å½±ç‰‡æ˜¯å¦æ’­æ”¾å®Œç•¢
    video_finished = 0

    # è³‡æ–™å„²å­˜æ ¼å¼
    # car_info : {
    #     car_id -> {
    #         frame_num -> {
    #             ori_imgs, 
    #             car_imgs, 
    #             bbboxes
    #         }
    #     }
    # }

    # åƒæ•¸è¨­å®š
    buffer_size = 16
    check_interval = 30
    ip = "localhost:8081"                     
    #########################

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error reading video file: {video_path}")
        return

    #output_videoçš„width, height, fpsè¨­å®š
    #width, height, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))
    
    #output_video_path = output_folder + "/video_output/" + filename + "_output.mp4"
    #print(output_video_path)

    #video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
    
    while True:
        success, frame = cap.read()
        if success:
            frame_num += 1
            #yoloV8å•Ÿå‹•
            results = model.track(frame, persist=True, tracker='bytetrack.yaml', classes = [2,7], verbose=False)
            #è¦å…ˆç¢ºèªå½±ç‰‡ä¸­æ˜¯å¦æœ‰åµæ¸¬åˆ°ç‰©ä»¶
            if results[0].boxes.id is not None:
                #boxesç‚ºé€™ä¸€å¹€æ‰€æœ‰bounding boxè³‡è¨Šï¼ˆä¸­å¿ƒåº§æ¨™ä»¥åŠw,h)çš„é›†åˆ
                #track_idsç‚ºé€™ä¸€å¹€æ‰€æœ‰idçš„é›†åˆ
                
                boxes = results[0].boxes.xywh.cpu()
                track_ids = results[0].boxes.id.int().cpu().tolist()

                #å°‡é æ¸¬çµæœå¯«å…¥å½±ç‰‡ï¼ˆå°±æ˜¯é‚£äº›æ¡†æ¡†ï¼‰
                annotated_frame = results[0].plot()
                cv2.putText(annotated_frame, str(frame_num), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255))
                #video_writer.write(annotated_frame)

                #ç´€éŒ„ç›®å‰çš„è»Šè¼›
                current_cars = set(track_ids)
                # print(current_cars, buffer)
                for box, track_id in zip(boxes, track_ids):
                    x, y, w, h = box
                    #è¨ˆç®—bounding boxå·¦ä¸Šè§’åŠå³ä¸‹è§’åº§æ¨™ä»¥ä¾›opencvæˆªåœ–
                    x1 = int(x - w / 2)
                    y1 = int(y - h / 2)
                    x2 = int(x1 + w)
                    y2 = int(y1 + h)
                    if x1 - 10 > 0:
                        x1 -= 10
                    else:
                        x1 = 0
                    if frame.shape[1] - x2 - 10 > 0:
                        x2 += 10
                    else:
                        x2 = frame.shape[1] - 1
                    
                    roi = frame[y1:y2, x1:x2]
                    roi = cv2.resize(roi, (224, 224))

                    #å°‡boxeså’Œcar_imgsä¸­çš„è³‡æ–™æ”¾å…¥car_info
                    car_info[track_id][frame_num] = {
                        "ori_imgs" :frame,  
                        "car_imgs" : roi,
                        "bboxes" : (x,y,w,h)
                    }
                #æ¯10å¹€åµæ¸¬ä¸€æ¬¡
                if frame_num%check_interval == 0:
                    disappeared_cars = record_cars - current_cars
                    record_cars = current_cars
                else:
                    disappeared_cars = set()
                #å°‡çµæŸçš„è»Šè¼›é€²å…¥buffer
                if disappeared_cars:
                    for car_id in disappeared_cars:
                        buffer.append(car_id)
        else:
            for car_id in record_cars:
                buffer.append(car_id)
            record_cars.clear()
            video_finished = 1
        if len(buffer) >= buffer_size:
            #åŸ·è¡Œè½‰å½åˆ¤æ–·åŠé•è¦åˆ¤æ–·
            print("åŸ·è¡Œè½‰å½åˆ¤æ–·çš„è»Šè¼›:", buffer[-buffer_size:])
            turn_info = {key: car_info[key] for key in buffer[-buffer_size:]}
            turn_cars = turn_predict(turn_model, turn_info)
            print("è½‰å½çš„è»Šè¼›", turn_cars)
            if turn_cars:
                light_info = {key: car_info[key] for key in turn_cars}
                light_cars = light_predict(light_model, light_info, output_folder, filename)
                if light_cars :
                    event_data = {
                        "event": "violation_car",
                        "car_id": light_cars,
                        "video_name": filename,
                        "video_path": video_path,
                        "auto": auto,
                        "source": video_source  # æ–°å¢ä¾†æº (video1, video2, video3, video4)
                    }
                    # å‚³é€è¨Šæ¯çµ¦å‰ç«¯ç¶²é (å¯¦æ™‚åµæ¸¬ç³»çµ±)
                    await websocket.send(json.dumps(event_data))
                    # å‚³é€è¨Šæ¯çµ¦PHPå¾Œç«¯(get_violation_car_data)
                    response = requests.post(os.path.join(ip,"get_violation_car_data"), json = event_data)
                print("æ²’æœ‰æ‰“æ–¹å‘ç‡ˆçš„è»Šè¼›:", light_cars)
            else:
                print("æ²’æœ‰æ‰“æ–¹å‘ç‡ˆçš„è»Šè¼›: none")
            print("")
            # ç§»é™¤buffer
            del buffer[-buffer_size:]

        if len(buffer) == 0 and video_finished == 1:
            break
        elif len(buffer) < buffer_size and video_finished == 1:
            print("åŸ·è¡Œæª¢æ¸¬çš„è»Šè¼›:", buffer)
            turn_info = {key: car_info[key] for key in buffer}
            turn_cars = turn_predict(turn_model, turn_info)
            print("è½‰å½çš„è»Šè¼›", turn_cars)
            if turn_cars:
                light_info = {key: car_info[key] for key in turn_cars}
                light_cars = light_predict(light_model, light_info, output_folder, filename)

                if light_cars :
                    event_data = {
                        "event": "violation_car",
                        "car_id": light_cars,
                        "video_name": filename,
                        "video_path": video_path,
                        "auto": auto    
                    }
                    # å‚³é€è¨Šæ¯çµ¦å‰ç«¯ç¶²é (å¯¦æ™‚åµæ¸¬ç³»çµ±)
                    await websocket.send(json.dumps(event_data))
                    # å‚³é€è¨Šæ¯çµ¦PHPå¾Œç«¯(get_violation_car_data)
                    #response = requests.post(os.path.join(ip,"get_violation_car_data"), json = event_data)
                    response = requests.post(f"http://{ip}/get_violation_car_data", json=event_data)

                print("æ²’æœ‰æ‰“æ–¹å‘ç‡ˆçš„è»Šè¼›:", light_cars)
            else:
                print("æ²’æœ‰æ‰“æ–¹å‘ç‡ˆçš„è»Šè¼›: none")
            buffer.clear()
            break

    model.predictor.trackers[0].reset()
    cap.release()
    #video_writer.release()
    cv2.destroyAllWindows()
    print(list(car_info.keys()))
    print(len(car_info))        

async def process_video_folder(folder_path, output_folder, video_source):
    """è®“ car_track() åŒæ™‚è™•ç†å››å€‹è³‡æ–™å¤¾å…§çš„å½±ç‰‡ """
    video_files = sorted(os.listdir(folder_path))  # è®€å–è³‡æ–™å¤¾å…§æ‰€æœ‰å½±ç‰‡
    tasks = []
    
    for video_file in video_files:
        video_path = os.path.join(folder_path, video_file)
        if not video_file.endswith(".mp4"):  # ç¢ºä¿åªè™•ç† mp4 æª”æ¡ˆ
            continue
        print(f"è™•ç†å½±ç‰‡ {video_path} å°æ‡‰ {video_source}")

        # **åŒæ™‚åŸ·è¡Œå¤šå€‹å½±ç‰‡åˆ†æ**
        tasks.append(car_track(video_path, output_folder, None, 1, video_source))

    await asyncio.gather(*tasks)  # **è®“æ‰€æœ‰ car_track() åŒæ™‚åŸ·è¡Œ**

async def start_all_video_processing():
    with open(log_path, "a", encoding="utf-8") as f:
        f.write("ğŸ“ é–‹å§‹è™•ç†å››å€‹è³‡æ–™å¤¾çš„å½±ç‰‡...\n")

    """ è®“å››å€‹è³‡æ–™å¤¾å…§çš„å½±ç‰‡åŒæ™‚é€²è¡Œé•è¦åµæ¸¬ """
    VIDEO_PATH = VIDEO_PATH = os.path.join(os.getcwd(), "public", "videos")


    if not os.path.exists(VIDEO_PATH):
        print(f"âŒ éŒ¯èª¤: å½±ç‰‡ä¾†æºè³‡æ–™å¤¾ {VIDEO_PATH} ä¸å­˜åœ¨ï¼è«‹ç¢ºèªè·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚")
        return
    
    tasks = [
        process_video_folder(os.path.join(VIDEO_PATH, "folder1"), os.path.join(os.getcwd(), "public", "videos"), "video1"),
        process_video_folder(os.path.join(VIDEO_PATH, "folder2"), os.path.join(os.getcwd(), "public", "videos"), "video2"),
        process_video_folder(os.path.join(VIDEO_PATH, "folder3"), os.path.join(os.getcwd(), "public", "videos"), "video3"),
        process_video_folder(os.path.join(VIDEO_PATH, "folder4"), os.path.join(os.getcwd(), "public", "videos"), "video4"),
    ]

    await asyncio.gather(*tasks)    

if __name__ == "__main__":
    with open(log_path, "a", encoding="utf-8") as f:
        f.write("âœ… é€²å…¥ __main__ï¼Œå³å°‡åŸ·è¡Œ asyncio.run()\n")

    asyncio.run(start_all_video_processing())  # å•Ÿå‹•å››å€‹è³‡æ–™å¤¾åŒæ™‚è™•ç† 


